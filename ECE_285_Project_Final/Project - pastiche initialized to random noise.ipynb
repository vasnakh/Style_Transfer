{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        a, b, c, d = input.size()\n",
    "        features = input.view(a * b, c * d)\n",
    "        G = torch.mm(features, features.t())\n",
    "        return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style transfer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransferNetwork(object):\n",
    "    def __init__(self, content,  multi_styles):\n",
    "        super(StyleTransferNetwork, self).__init__()\n",
    "        self.num_of_convs_for_style = 5    # change this to account for the number of convolution layers used for style\n",
    "        self.num_styles = len(multi_styles) # the number of styles we want to transfer to content\n",
    "        self.mult_style_weight = [0] * self.num_styles  # weights according to average weighting of style loss\n",
    "        self.styles = multi_styles\n",
    "        self.log = 0 # for logging the loss which will be used to plot log-loss\n",
    "        self.content = content\n",
    "\n",
    "        self.pastiche = Variable((torch.randn(content.size())).type_as(content.data), requires_grad=True) # use for\n",
    "        # random initialization\n",
    "\n",
    "        self.content_layers = ['conv_3_1']\n",
    "        self.style_layers = []\n",
    "        self.style_layers = ['conv_1_1', 'conv_1_2', 'conv_2_1', 'conv_2_2', 'conv_3_1'] # if you want to manually\n",
    "\n",
    "        # change the layers used for style loss uncomment last line and comment out the for loop in next line\n",
    "        # for i in range(0, self.num_of_convs_for_style):\n",
    "        #      self.style_layers.append(\"conv_\" + str(i+1) + \"_1\")\n",
    "\n",
    "\n",
    "        # this line if random initialization is used\n",
    "        self.style_loss_weight = [1] * self.num_of_convs_for_style\n",
    "        # self.style_loss_weight = [n / (self.num_of_convs_for_style) for n in [64, 64, 128, 128, 256]]\n",
    "\n",
    "\n",
    "        self.content_weight = 1     # this is alpha according to the paper\n",
    "        self.style_weight = 1000    # this is beta according to paper\n",
    "\n",
    "        self.loss_network = models.vgg19(pretrained=True)\n",
    "        for param in self.loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.gram = GramMatrix()\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = optim.Adamax([self.pastiche])\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.loss_network.cuda()\n",
    "            self.gram.cuda()\n",
    "\n",
    "    def train(self):\n",
    "        def closure():\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            pastiche = self.pastiche\n",
    "\n",
    "            # the following two lines are used for clamping the pastiche to be between 0 and 1, uncomment when pastiche\n",
    "            # is initialized to random noise\n",
    "            pastiche.data[pastiche.data > 1] = 1\n",
    "            pastiche.data[pastiche.data < 0] = 0\n",
    "\n",
    "\n",
    "            content = self.content.clone()\n",
    "            styles_to_transfer = []\n",
    "            for z in range(0, self.num_styles):\n",
    "                styles_to_transfer.append(self.styles[z].clone())\n",
    "            styles_loss = torch.zeros(self.num_styles).type(dtype)\n",
    "            content_loss = 0\n",
    "            j = 0\n",
    "            i = 1\n",
    "            layer_count = 1\n",
    "            not_inplace = lambda layer: nn.ReLU(inplace=False) if isinstance(layer, nn.ReLU) else layer\n",
    "            for layer in list(self.loss_network.features):\n",
    "                layer = not_inplace(layer)\n",
    "                if self.use_cuda:\n",
    "                    layer.cuda()\n",
    "\n",
    "                pastiche, content = layer.forward(pastiche), layer.forward(content)\n",
    "\n",
    "                for z in range(0, self.num_styles):\n",
    "                    styles_to_transfer[z] = layer.forward(styles_to_transfer[z])\n",
    "\n",
    "                if isinstance(layer, nn.Conv2d):\n",
    "                    name = \"conv_\" + str(layer_count) + \"_\" + str(i)\n",
    "                    if name in self.content_layers:\n",
    "                        content_loss += self.loss(pastiche, content.detach())\n",
    "\n",
    "                    if name in self.style_layers:\n",
    "                        pastiche_g = self.gram.forward(pastiche)\n",
    "                        for z in range(0, self.num_styles):\n",
    "                            style_g = self.gram.forward(styles_to_transfer[z])\n",
    "                            styles_loss[z] += self.style_loss_weight[j] * self.loss(self.style_weight *pastiche_g,\n",
    "                                                                                    self.style_weight *style_g.detach())\n",
    "                        j += 1\n",
    "                if isinstance(layer, nn.ReLU):\n",
    "                    i += 1\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer_count += 1\n",
    "                    i = 1\n",
    "            tot_style_loss = sum(styles_loss)\n",
    "            total_loss = self.content_weight * content_loss\n",
    "            for z in range(0, self.num_styles):\n",
    "\n",
    "                #self.mult_style_weight[z] = 1.0 / self.num_styles  # uncomment this line and comment out next\n",
    "                # if custom (equal in this case) weight is needed for each style\n",
    "\n",
    "                self.mult_style_weight[z] = styles_loss[z]/tot_style_loss # comment out if custom weights for each style\n",
    "                # is needed\n",
    "                total_loss +=  self.mult_style_weight[z] * styles_loss[z]\n",
    "            total_loss.backward()\n",
    "            self.log = total_loss\n",
    "            return total_loss\n",
    "\n",
    "        self.optimizer.step(closure)\n",
    "        return self.pastiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "\n",
    "pre_process = transforms.Compose([transforms.Resize((imsize, imsize)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Image Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_a = transforms.Compose([])\n",
    "\n",
    "\n",
    "post_process_b = transforms.Compose([transforms.ToPILImage()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postp(tensor):\n",
    "    t = post_process_a(tensor)\n",
    "    t[t > 1] = 1 # to clamp results in the range [0,1]\n",
    "    t[t < 0] = 0 # to clamp results in the range [0,1]\n",
    "    img = post_process_b(t)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_styles(path):\n",
    "    styles = []\n",
    "    for file in glob.glob(path+\"/*.jpg\"):\n",
    "        styles.append(image_loader(file).type(dtype))\n",
    "\n",
    "    return styles\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = pre_process(image)\n",
    "    image = Variable(image.unsqueeze(0))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    path_styles = \"./styles\"\n",
    "    path_contents = \"./contents\"\n",
    "    out_path = \"./outputs\"\n",
    "    num_epochs = 20000\n",
    "    styles = load_styles(path_styles)\n",
    "    for cont_file in glob.glob(path_contents + \"/*.jpg\"):\n",
    "        log = []\n",
    "        content = image_loader(cont_file).type(dtype)\n",
    "\n",
    "        style_cnn = StyleTransferNetwork(content, styles)\n",
    "        out_counter = 0\n",
    "        for i in range(num_epochs + 1):\n",
    "            pastiche = style_cnn.train()\n",
    "\n",
    "            log.append([i, style_cnn.log.item()])\n",
    "            if i % 1000 == 0:\n",
    "                print(str(style_cnn.log.item()) + \" \" + str(i))\n",
    "                print(\"Iteration: %d\" % i)\n",
    "                cont_name = cont_file.replace('./contents\\\\', \"\")\n",
    "                cont_name = cont_name.replace(\".jpg\", \"\")\n",
    "                path = out_path + \"/\" + cont_name + \"_%d.png\" % out_counter\n",
    "                out_img = postp(pastiche.data[0].cpu().squeeze())\n",
    "                scipy.misc.imsave(path, out_img)\n",
    "                out_counter += 1\n",
    "        a = np.array(log)\n",
    "        plt.figure(2)\n",
    "        plt.plot(a[1:, 0], np.log(a[1:, 1]))\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('loss(log)')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41095.8828125 0\n",
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487.0604248046875 1000\n",
      "Iteration: 1000\n",
      "270.358642578125 2000\n",
      "Iteration: 2000\n",
      "219.71609497070312 3000\n",
      "Iteration: 3000\n",
      "199.4637451171875 4000\n",
      "Iteration: 4000\n",
      "189.59622192382812 5000\n",
      "Iteration: 5000\n",
      "184.3130645751953 6000\n",
      "Iteration: 6000\n",
      "181.52590942382812 7000\n",
      "Iteration: 7000\n",
      "179.90655517578125 8000\n",
      "Iteration: 8000\n",
      "179.12152099609375 9000\n",
      "Iteration: 9000\n",
      "178.87030029296875 10000\n",
      "Iteration: 10000\n",
      "178.78350830078125 11000\n",
      "Iteration: 11000\n",
      "178.740478515625 12000\n",
      "Iteration: 12000\n",
      "178.712890625 13000\n",
      "Iteration: 13000\n",
      "178.69229125976562 14000\n",
      "Iteration: 14000\n",
      "178.67752075195312 15000\n",
      "Iteration: 15000\n",
      "178.66590881347656 16000\n",
      "Iteration: 16000\n",
      "178.6578826904297 17000\n",
      "Iteration: 17000\n",
      "178.651123046875 18000\n",
      "Iteration: 18000\n",
      "178.64671325683594 19000\n",
      "Iteration: 19000\n",
      "178.64129638671875 20000\n",
      "Iteration: 20000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b931fbacf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
