{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        a, b, c, d = input.size()\n",
    "        features = input.view(a * b, c * d)\n",
    "        G = torch.mm(features, features.t())\n",
    "        return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style transfer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransferNetwork(object):\n",
    "    def __init__(self, content,  multi_styles):\n",
    "        super(StyleTransferNetwork, self).__init__()\n",
    "        self.num_of_convs_for_style = 5    # change this to account for the number of convolution layers used for style\n",
    "        self.num_styles = len(multi_styles) # the number of styles we want to transfer to content\n",
    "        self.mult_style_weight = [0] * self.num_styles  # weights according to average weighting of style loss\n",
    "        self.styles = multi_styles\n",
    "        self.log = 0 # for logging the loss which will be used to plot log-loss\n",
    "        self.content = content\n",
    "\n",
    "        self.pastiche = Variable((torch.randn(content.size())).type_as(content.data), requires_grad=True) # use for\n",
    "        # random initialization\n",
    "\n",
    "        self.content_layers = ['conv_3_1']\n",
    "        self.style_layers = []\n",
    "        self.style_layers = ['conv_1_1', 'conv_1_2', 'conv_2_1', 'conv_2_2', 'conv_3_1'] # if you want to manually\n",
    "\n",
    "        # change the layers used for style loss uncomment last line and comment out the for loop in next line\n",
    "        # for i in range(0, self.num_of_convs_for_style):\n",
    "        #      self.style_layers.append(\"conv_\" + str(i+1) + \"_1\")\n",
    "\n",
    "\n",
    "        \n",
    "        self.style_loss_weight = [1] * self.num_of_convs_for_style\n",
    "        # self.style_loss_weight = [n / (self.num_of_convs_for_style) for n in [64, 64, 128, 128, 256]]\n",
    "\n",
    "\n",
    "        self.content_weight = 1     # this is alpha according to the paper\n",
    "        self.style_weight = 1000    # this is beta according to paper\n",
    "\n",
    "        self.loss_network = models.vgg19(pretrained=True)\n",
    "        for param in self.loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.gram = GramMatrix()\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = optim.Adamax([self.pastiche])\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.loss_network.cuda()\n",
    "            self.gram.cuda()\n",
    "\n",
    "    def train(self):\n",
    "        def closure():\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            pastiche = self.pastiche\n",
    "\n",
    "            # the following two lines are used for clamping the pastiche to be between 0 and 1, uncomment when pastiche\n",
    "            # is initialized to random noise\n",
    "            pastiche.data[pastiche.data > 1] = 1\n",
    "            pastiche.data[pastiche.data < 0] = 0\n",
    "\n",
    "\n",
    "            content = self.content.clone()\n",
    "            styles_to_transfer = []\n",
    "            for z in range(0, self.num_styles):\n",
    "                styles_to_transfer.append(self.styles[z].clone())\n",
    "            styles_loss = Variable(torch.zeros(self.num_styles).type(dtype))\n",
    "            content_loss = 0\n",
    "            j = 0\n",
    "            i = 1\n",
    "            layer_count = 1\n",
    "            not_inplace = lambda layer: nn.ReLU(inplace=False) if isinstance(layer, nn.ReLU) else layer\n",
    "            for layer in list(self.loss_network.features):\n",
    "                layer = not_inplace(layer)\n",
    "                if self.use_cuda:\n",
    "                    layer.cuda()\n",
    "\n",
    "                pastiche, content = layer.forward(pastiche), layer.forward(content)\n",
    "\n",
    "                for z in range(0, self.num_styles):\n",
    "                    styles_to_transfer[z] = layer.forward(styles_to_transfer[z])\n",
    "\n",
    "                if isinstance(layer, nn.Conv2d):\n",
    "                    name = \"conv_\" + str(layer_count) + \"_\" + str(i)\n",
    "                    if name in self.content_layers:\n",
    "                        content_loss += self.loss(pastiche, content.detach())\n",
    "\n",
    "                    if name in self.style_layers:\n",
    "                        pastiche_g = self.gram.forward(pastiche)\n",
    "                        for z in range(0, self.num_styles):\n",
    "                            style_g = self.gram.forward(styles_to_transfer[z])\n",
    "                            styles_loss[z] =styles_loss[z]+ self.style_loss_weight[j] * self.loss(self.style_weight *pastiche_g,\n",
    "                                                                                    self.style_weight *style_g.detach())\n",
    "                        j += 1\n",
    "                if isinstance(layer, nn.ReLU):\n",
    "                    i += 1\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer_count += 1\n",
    "                    i = 1\n",
    "            tot_style_loss = sum(styles_loss)\n",
    "            total_loss = self.content_weight * content_loss\n",
    "            for z in range(0, self.num_styles):\n",
    "\n",
    "                #self.mult_style_weight[z] = 1.0 / self.num_styles  # uncomment this line and comment out next\n",
    "                # if custom (equal in this case) weight is needed for each style\n",
    "\n",
    "                self.mult_style_weight[z] = styles_loss[z]/tot_style_loss # comment out if custom weights for each style\n",
    "                # is needed\n",
    "                total_loss +=  self.mult_style_weight[z] * styles_loss[z]\n",
    "            total_loss.backward()\n",
    "            self.log = total_loss\n",
    "            return total_loss\n",
    "\n",
    "        self.optimizer.step(closure)\n",
    "        return self.pastiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "\n",
    "pre_process = transforms.Compose([transforms.Resize((imsize, imsize)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Image Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_a = transforms.Compose([])\n",
    "\n",
    "\n",
    "post_process_b = transforms.Compose([transforms.ToPILImage()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postp(tensor):\n",
    "    t = post_process_a(tensor)\n",
    "    t[t > 1] = 1 # to clamp results in the range [0,1]\n",
    "    t[t < 0] = 0 # to clamp results in the range [0,1]\n",
    "    img = post_process_b(t)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_styles(path):\n",
    "    styles = []\n",
    "    for file in glob.glob(path+\"/*.jpg\"):\n",
    "        styles.append(image_loader(file).type(dtype))\n",
    "\n",
    "    return styles\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = pre_process(image)\n",
    "    image = Variable(image.unsqueeze(0))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    path_styles = \"./styles\"\n",
    "    path_contents = \"./contents\"\n",
    "    out_path = \"./outputs\"\n",
    "    num_epochs = 20000\n",
    "    styles = load_styles(path_styles)\n",
    "    for cont_file in glob.glob(path_contents + \"/*.jpg\"):\n",
    "        log = []\n",
    "        content = image_loader(cont_file).type(dtype)\n",
    "\n",
    "        style_cnn = StyleTransferNetwork(content, styles)\n",
    "        out_counter = 0\n",
    "        for i in range(num_epochs + 1):\n",
    "            pastiche = style_cnn.train()\n",
    "\n",
    "            log.append([i, style_cnn.log.data.cpu().numpy()[0]])\n",
    "            if i % 1000 == 0:\n",
    "                print (str(style_cnn.log.data.cpu().numpy()[0] )+ \" \" + str(i))\n",
    "                #print \"Iteration: %d\" % i\n",
    "                cont_name = cont_file.replace('./contents/', \"\")\n",
    "                cont_name = cont_name.replace(\".jpg\", \"\")\n",
    "                path = out_path + \"/\" + cont_name + \"_%d.png\" % out_counter\n",
    "                out_img = postp(pastiche.data[0].cpu().squeeze())\n",
    "                scipy.misc.imsave(path, out_img)\n",
    "                out_counter += 1\n",
    "        a = np.array(log)\n",
    "        plt.figure(2)\n",
    "        plt.plot(a[1:, 0], np.log(a[1:, 1]))\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('loss(log)')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40380.406 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480.4405 1000\n",
      "268.08038 2000\n",
      "218.87086 3000\n",
      "199.39032 4000\n",
      "189.73651 5000\n",
      "184.42783 6000\n",
      "181.52002 7000\n",
      "179.93503 8000\n",
      "179.1735 9000\n",
      "178.93079 10000\n",
      "178.84262 11000\n",
      "178.79575 12000\n",
      "178.76277 13000\n",
      "178.7428 14000\n",
      "178.72916 15000\n",
      "178.71402 16000\n",
      "178.7042 17000\n",
      "178.69641 18000\n",
      "178.6896 19000\n",
      "178.68309 20000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
