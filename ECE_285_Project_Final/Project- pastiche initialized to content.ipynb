{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        a, b, c, d = input.size()\n",
    "        features = input.view(a * b, c * d)\n",
    "        G = torch.mm(features, features.t())\n",
    "        return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style transfer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransferNetwork(object):\n",
    "    def __init__(self, content,  multi_styles):\n",
    "        super(StyleTransferNetwork, self).__init__()\n",
    "        self.num_of_convs_for_style = 5    # change this to account for the number of convolution layers used for style\n",
    "        self.num_styles = len(multi_styles) # the number of styles we want to transfer to content\n",
    "        self.mult_style_weight = [0] * self.num_styles  # weights according to average weighting of style loss\n",
    "        self.styles = multi_styles\n",
    "        self.log = 0 # logging the loss which will be used to plot log-loss\n",
    "        self.content = content\n",
    "\n",
    "        \n",
    "        self.pastiche = Variable(content.data.clone(), requires_grad=True) # use this to initialize pastiche to content\n",
    "\n",
    "        self.content_layers = ['conv_4_2']\n",
    "        self.style_layers = []\n",
    "\n",
    "        #self.style_layers = ['conv_1_1', 'conv_1_2', 'conv_2_1', 'conv_2_2', 'conv_3_1'] # if you want to manually\n",
    "        # change the layers used for style loss uncomment this line and comment out the for loop in next line\n",
    "\n",
    "        for i in range(0, self.num_of_convs_for_style):\n",
    "             self.style_layers.append(\"conv_\" + str(i+1) + \"_1\")\n",
    "\n",
    "        \n",
    "        self.style_loss_weight = [1.0 / (self.num_of_convs_for_style)] * self.num_of_convs_for_style\n",
    "\n",
    "        \n",
    "#         self.style_loss_weight = [n / (self.num_of_convs_for_style) for n in [64, 64, 128, 128, 256]]\n",
    "        self.content_weight = 1     # this is alpha according to the paper\n",
    "        self.style_weight = 1000    # this is beta according to paper\n",
    "\n",
    "        self.loss_network = models.vgg19(pretrained=True)\n",
    "        for param in self.loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.gram = GramMatrix()\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = optim.LBFGS([self.pastiche])\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.loss_network.cuda()\n",
    "            self.gram.cuda()\n",
    "\n",
    "    def train(self):\n",
    "        def closure():\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            pastiche = self.pastiche\n",
    "\n",
    "            content = self.content.clone()\n",
    "            styles_to_transfer = []\n",
    "            for z in range(0, self.num_styles):\n",
    "                styles_to_transfer.append(self.styles[z].clone())\n",
    "            styles_loss = Variable(torch.zeros(self.num_styles).type(dtype))\n",
    "            content_loss = 0\n",
    "            j = 0\n",
    "            i = 1\n",
    "            layer_count = 1\n",
    "            not_inplace = lambda layer: nn.ReLU(inplace=False) if isinstance(layer, nn.ReLU) else layer\n",
    "            for layer in list(self.loss_network.features):\n",
    "                layer = not_inplace(layer)\n",
    "                if self.use_cuda:\n",
    "                    layer.cuda()\n",
    "\n",
    "                pastiche, content = layer.forward(pastiche), layer.forward(content)\n",
    "\n",
    "                for z in range(0, self.num_styles):\n",
    "                    styles_to_transfer[z] = layer.forward(styles_to_transfer[z])\n",
    "\n",
    "                if isinstance(layer, nn.Conv2d):\n",
    "                    name = \"conv_\" + str(layer_count) + \"_\" + str(i)\n",
    "                    if name in self.content_layers:\n",
    "                        content_loss += self.loss(pastiche, content.detach())\n",
    "\n",
    "                    if name in self.style_layers:\n",
    "                        pastiche_g = self.gram.forward(pastiche)\n",
    "                        for z in range(0, self.num_styles):\n",
    "                            style_g = self.gram.forward(styles_to_transfer[z])\n",
    "                            styles_loss[z] =styles_loss[z] + self.style_loss_weight[j] * self.loss(pastiche_g,\n",
    "                                                                                    style_g.detach())\n",
    "                        j += 1\n",
    "                if isinstance(layer, nn.ReLU):\n",
    "                    i += 1\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer_count += 1\n",
    "                    i = 1\n",
    "            tot_style_loss = sum(styles_loss)\n",
    "            total_loss = self.content_weight * content_loss\n",
    "            for z in range(0, self.num_styles):\n",
    "\n",
    "                #self.mult_style_weight[z] = 1.0 / self.num_styles  # uncomment this line and comment out next\n",
    "                # if custom (equal in this case) weight is needed for each style\n",
    "\n",
    "                self.mult_style_weight[z] = styles_loss[z]/tot_style_loss # comment out if custom weights for each style\n",
    "                # is needed\n",
    "                total_loss += self.style_weight * self.mult_style_weight[z] * styles_loss[z]\n",
    "            total_loss.backward()\n",
    "            self.log = total_loss\n",
    "            return total_loss\n",
    "\n",
    "        self.optimizer.step(closure)\n",
    "        return self.pastiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "\n",
    "mean_imgnet = [123.68/255, 116.779/255, 103.939/255]\n",
    "neg_mean_imgnet = [-123.68/255, -116.779/255, -103.939/255]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pre_process = transforms.Compose([transforms.Resize((imsize, imsize)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=mean_imgnet, # subtract imagenet mean and normalize\n",
    "                                                std=[1,1,1]),\n",
    "                                  transforms.Lambda(lambda x: x.mul_(255)),  # to have the range from [-255, 255]\n",
    "                                  ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Image Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_a = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1. / 255)),  # convert back from [-255, 255]\n",
    "                                     transforms.Normalize(mean=neg_mean_imgnet, # add imagenet mean back\n",
    "                                                std=[1,1,1]),\n",
    "                                     ])\n",
    "\n",
    "\n",
    "post_process_b = transforms.Compose([transforms.ToPILImage()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postp(tensor):\n",
    "    t = post_process_a(tensor)\n",
    "    t[t > 1] = 1 # to clamp results in the range [0,1]\n",
    "    t[t < 0] = 0 # to clamp results in the range [0,1]\n",
    "    img = post_process_b(t)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_styles(path):\n",
    "    styles = []\n",
    "    for file in glob.glob(path+\"/*.jpg\"):\n",
    "        styles.append(image_loader(file).type(dtype))\n",
    "\n",
    "    return styles\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = pre_process(image)\n",
    "    image = Variable(image.unsqueeze(0))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    path_styles = \"./styles\"\n",
    "    path_contents = \"./contents\"\n",
    "    out_path = \"./outputs\"\n",
    "    num_epochs = 50\n",
    "    styles = load_styles(path_styles)\n",
    "    for cont_file in glob.glob(path_contents + \"/*.jpg\"):\n",
    "        log = []\n",
    "        content = image_loader(cont_file).type(dtype)\n",
    "\n",
    "        style_cnn = StyleTransferNetwork(content, styles)\n",
    "        out_counter = 0\n",
    "        for i in range(num_epochs + 1):\n",
    "            pastiche = style_cnn.train()\n",
    "            print(str(style_cnn.log.data.cpu().numpy()[0]) + \" \" + str(i))\n",
    "            log.append([i, style_cnn.log.data.cpu().numpy()[0]])\n",
    "            if i % 10 == 0:\n",
    "                print \"Iteration: \" , i\n",
    "                cont_name = cont_file.replace('./contents/', \"\")\n",
    "                cont_name = cont_name.replace(\".jpg\", \"\")\n",
    "                path = out_path + \"/\" + cont_name + \"_%d.png\" % out_counter\n",
    "                out_img = postp(pastiche.data[0].cpu().squeeze())\n",
    "                scipy.misc.imsave(path, out_img)\n",
    "                out_counter += 1\n",
    "        a = np.array(log)\n",
    "        plt.figure(2)\n",
    "        plt.plot(a[1:, 0], np.log(a[1:, 1]))\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('loss(log)')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15421516.0 0\n",
      "Iteration:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13712370.0 1\n",
      "13361236.0 2\n",
      "13239568.0 3\n",
      "13185068.0 4\n",
      "13154082.0 5\n",
      "13130258.0 6\n",
      "13114930.0 7\n",
      "13101422.0 8\n",
      "13091360.0 9\n",
      "13082740.0 10\n",
      "Iteration:  10\n",
      "13075776.0 11\n",
      "13070560.0 12\n",
      "13065896.0 13\n",
      "13062211.0 14\n",
      "13058646.0 15\n",
      "13056143.0 16\n",
      "13053716.0 17\n",
      "13051740.0 18\n",
      "13049924.0 19\n",
      "13048477.0 20\n",
      "Iteration:  20\n",
      "13047162.0 21\n",
      "13045968.0 22\n",
      "13044944.0 23\n",
      "13044054.0 24\n",
      "13043194.0 25\n",
      "13042500.0 26\n",
      "13041847.0 27\n",
      "13041232.0 28\n",
      "13040710.0 29\n",
      "13040202.0 30\n",
      "Iteration:  30\n",
      "13039779.0 31\n",
      "13039356.0 32\n",
      "13038997.0 33\n",
      "13038637.0 34\n",
      "13038314.0 35\n",
      "13038016.0 36\n",
      "13037746.0 37\n",
      "13037489.0 38\n",
      "13037244.0 39\n",
      "13037022.0 40\n",
      "Iteration:  40\n",
      "13036806.0 41\n",
      "13036613.0 42\n",
      "13036433.0 43\n",
      "13036261.0 44\n",
      "13036106.0 45\n",
      "13035954.0 46\n",
      "13035808.0 47\n",
      "13035670.0 48\n",
      "13035542.0 49\n",
      "13035418.0 50\n",
      "Iteration:  50\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
