{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        a, b, c, d = input.size()\n",
    "        features = input.view(a * b, c * d)\n",
    "        G = torch.mm(features, features.t())\n",
    "        return G.div(a * b * c * d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style transfer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransferNetwork(object):\n",
    "    def __init__(self, content,  multi_styles):\n",
    "        super(StyleTransferNetwork, self).__init__()\n",
    "        self.num_of_convs_for_style = 5    # change this to account for the number of convolution layers used for style\n",
    "        self.num_styles = len(multi_styles) # the number of styles we want to transfer to content\n",
    "        self.mult_style_weight = [0] * self.num_styles  # weights according to average weighting of style loss\n",
    "        self.styles = multi_styles\n",
    "        self.log = 0\n",
    "        self.content = content\n",
    "\n",
    "        #self.pastiche = Variable((torch.randn(content.size())).type_as(content.data), requires_grad=True) # use for\n",
    "        # random initialization\n",
    "        self.pastiche = Variable(content.data.clone(), requires_grad=True) # use this to initialize pastiche to content\n",
    "\n",
    "        self.content_layers = ['conv_4_2']\n",
    "        self.style_layers = []\n",
    "\n",
    "        #self.style_layers = ['conv_1_1', 'conv_1_2', 'conv_2_1', 'conv_2_2', 'conv_3_1'] # if you want to manually\n",
    "        # change the layers used for style loss uncomment this line and comment out the for loop in next line\n",
    "\n",
    "        for i in range(0, self.num_of_convs_for_style):\n",
    "             self.style_layers.append(\"conv_\" + str(i+1) + \"_1\")\n",
    "\n",
    "        #self.style_loss_weight = [1.0 / (1000 * self.num_of_convs_for_style)] * self.num_of_convs_for_style # uncomment\n",
    "        # this line if random initialization is used\n",
    "        self.style_loss_weight = [1.0 / (self.num_of_convs_for_style)] * self.num_of_convs_for_style\n",
    "\n",
    "        #self.style_loss_weight = [1 / (self.num_of_convs_for_style*n**2) for n in [64, 128, 256, 512, 512]]\n",
    "        self.content_weight = 1     # this is alpha according to the paper\n",
    "        self.style_weight = 1000    # this is beta according to paper\n",
    "\n",
    "        self.loss_network = models.vgg19(pretrained=True)\n",
    "        for param in self.loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.gram = GramMatrix()\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = optim.LBFGS([self.pastiche])\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.loss_network.cuda()\n",
    "            self.gram.cuda()\n",
    "\n",
    "    def train(self):\n",
    "        def closure():\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            pastiche = self.pastiche\n",
    "\n",
    "            # the following two lines are used for clamping the pastiche to be between 1 and -1, uncomment when pastiche\n",
    "            # is initialized to random noise\n",
    "            # pastiche.data[pastiche.data > 1] = 1\n",
    "            # pastiche.data[pastiche.data < -1] = -1\n",
    "\n",
    "\n",
    "            content = self.content.clone()\n",
    "            styles_to_transfer = []\n",
    "            for z in range(0, self.num_styles):\n",
    "                styles_to_transfer.append(self.styles[z].clone())\n",
    "            styles_loss = torch.zeros(self.num_styles).type(dtype)\n",
    "            content_loss = 0\n",
    "            j = 0\n",
    "            i = 1\n",
    "            layer_count = 1\n",
    "            not_inplace = lambda layer: nn.ReLU(inplace=False) if isinstance(layer, nn.ReLU) else layer\n",
    "            for layer in list(self.loss_network.features):\n",
    "                layer = not_inplace(layer)\n",
    "                if self.use_cuda:\n",
    "                    layer.cuda()\n",
    "\n",
    "                pastiche, content = layer.forward(pastiche), layer.forward(content)\n",
    "\n",
    "                for z in range(0, self.num_styles):\n",
    "                    styles_to_transfer[z] = layer.forward(styles_to_transfer[z])\n",
    "\n",
    "                if isinstance(layer, nn.Conv2d):\n",
    "                    name = \"conv_\" + str(layer_count) + \"_\" + str(i)\n",
    "                    if name in self.content_layers:\n",
    "                        content_loss += self.loss(pastiche, content.detach())\n",
    "\n",
    "                    if name in self.style_layers:\n",
    "                        pastiche_g = self.gram.forward(pastiche)\n",
    "                        for z in range(0, self.num_styles):\n",
    "                            style_g = self.gram.forward(styles_to_transfer[z])\n",
    "                            styles_loss[z] += self.style_loss_weight[j] * self.loss(pastiche_g,\n",
    "                                                                                    style_g.detach())\n",
    "                        j += 1\n",
    "                if isinstance(layer, nn.ReLU):\n",
    "                    i += 1\n",
    "                if isinstance(layer, nn.MaxPool2d):\n",
    "                    layer_count += 1\n",
    "                    i = 1\n",
    "            tot_style_loss = sum(styles_loss)\n",
    "            total_loss = self.content_weight * content_loss\n",
    "            for z in range(0, self.num_styles):\n",
    "\n",
    "                #self.mult_style_weight[z] = 1.0 / self.num_styles  # uncomment this line and comment out next\n",
    "                # if custom (equal in this case) weight is needed for each style\n",
    "\n",
    "                self.mult_style_weight[z] = styles_loss[z]/tot_style_loss # comment out if custom weights for each style\n",
    "                # is needed\n",
    "                total_loss += self.style_weight * self.mult_style_weight[z] * styles_loss[z]\n",
    "            total_loss.backward()\n",
    "            self.log = total_loss\n",
    "            return total_loss\n",
    "\n",
    "        self.optimizer.step(closure)\n",
    "        return self.pastiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "\n",
    "mean_imgnet = [123.68/255, 116.779/255, 103.939/255]\n",
    "neg_mean_imgnet = [-123.68/255, -116.779/255, -103.939/255]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pre_process = transforms.Compose([transforms.Resize((imsize, imsize)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=mean_imgnet, # subtract imagenet mean and normalize\n",
    "                                                std=[1,1,1]),\n",
    "                                  transforms.Lambda(lambda x: x.mul_(255)),  # to have the range from [-255, 255]\n",
    "                                  ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Image Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_a = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1. / 255)),  # convert back from [-255, 255]\n",
    "                                     transforms.Normalize(mean=neg_mean_imgnet, # add imagenet mean back\n",
    "                                                std=[1,1,1]),\n",
    "                                     ])\n",
    "\n",
    "\n",
    "post_process_b = transforms.Compose([transforms.ToPILImage()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postp(tensor):\n",
    "    t = post_process_a(tensor)\n",
    "    t[t > 1] = 1 # to clamp results in the range [0,1]\n",
    "    t[t < 0] = 0 # to clamp results in the range [0,1]\n",
    "    img = post_process_b(t)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_styles(path):\n",
    "    styles = []\n",
    "    for file in glob.glob(path+\"/*.jpg\"):\n",
    "        styles.append(image_loader(file).type(dtype))\n",
    "\n",
    "    return styles\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = pre_process(image)\n",
    "    image = Variable(image.unsqueeze(0))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    path_styles = \"./styles\"\n",
    "    path_contents = \"./contents\"\n",
    "    out_path = \"./outputs\"\n",
    "    num_epochs = 50\n",
    "    styles = load_styles(path_styles)\n",
    "    for cont_file in glob.glob(path_contents + \"/*.jpg\"):\n",
    "        log = []\n",
    "        content = image_loader(cont_file).type(dtype)\n",
    "\n",
    "        style_cnn = StyleTransferNetwork(content, styles)\n",
    "        out_counter = 0\n",
    "        for i in range(num_epochs + 1):\n",
    "            pastiche = style_cnn.train()\n",
    "            print(str(style_cnn.log.item()) + \" \" + str(i))\n",
    "            log.append([i, style_cnn.log.item()])\n",
    "            if i % 10 == 0:\n",
    "                print(\"Iteration: %d\" % i)\n",
    "                cont_name = cont_file.replace('./contents\\\\', \"\")\n",
    "                cont_name = cont_name.replace(\".jpg\", \"\")\n",
    "                path = out_path + \"/\" + cont_name + \"_%d.png\" % out_counter\n",
    "                out_img = postp(pastiche.data[0].cpu().squeeze())\n",
    "                scipy.misc.imsave(path, out_img)\n",
    "                out_counter += 1\n",
    "        a = np.array(log)\n",
    "        plt.figure(2)\n",
    "        plt.plot(a[1:, 0], np.log(a[1:, 1]))\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('loss(log)')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7492239.0 0\n",
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500683.125 1\n",
      "764860.375 2\n",
      "506606.75 3\n",
      "384938.84375 4\n",
      "315434.3125 5\n",
      "270268.65625 6\n",
      "242663.6875 7\n",
      "223489.625 8\n",
      "208303.25 9\n",
      "196947.46875 10\n",
      "Iteration: 10\n",
      "188390.984375 11\n",
      "181333.578125 12\n",
      "175862.125 13\n",
      "171369.546875 14\n",
      "167719.90625 15\n",
      "164522.84375 16\n",
      "161677.1875 17\n",
      "159453.5 18\n",
      "157303.34375 19\n",
      "155540.171875 20\n",
      "Iteration: 20\n",
      "153873.46875 21\n",
      "152402.859375 22\n",
      "151142.546875 23\n",
      "149857.5625 24\n",
      "148756.515625 25\n",
      "147751.421875 26\n",
      "146857.765625 27\n",
      "146025.15625 28\n",
      "145260.9375 29\n",
      "144565.015625 30\n",
      "Iteration: 30\n",
      "143917.9375 31\n",
      "143285.09375 32\n",
      "142729.140625 33\n",
      "142216.875 34\n",
      "141710.90625 35\n",
      "141229.984375 36\n",
      "140806.375 37\n",
      "140397.515625 38\n",
      "140017.578125 39\n",
      "139652.71875 40\n",
      "Iteration: 40\n",
      "139286.359375 41\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
